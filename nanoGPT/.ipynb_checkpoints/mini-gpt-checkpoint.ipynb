{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# building mini chat-gpt\n",
    "\n",
    "Video: [Let's build GPT: from scratch, in code, spelled out.](https://youtu.be/kCc8FmEb1nY?list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&t=561) - Andrej Karpathy\n",
    "\n",
    "Paper: [Attention is All You Need](https://arxiv.org/abs/1706.03762)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"gpt.png\" width=\"600\" height=\"800\" style=\"margin-left:auto; margin-right:auto\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: explore the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('kanye_lyrics.txt', 'r') as f:\n",
    "    lyrics = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of dataset:     353441 characters\n"
     ]
    }
   ],
   "source": [
    "print('Length of dataset:    ', len(lyrics), 'characters')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1: view the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 1000 characters:\n",
      "  ﻿[Chorus]\n",
      "Sing every hour (Every hour, 'til the power)\n",
      "Every minute (Every minute, of the Lord)\n",
      "Every second (Every second, comes)\n",
      "Sing each and every millisecond (Down)\n",
      "We need you (We need you, sing 'til the power)\n",
      "We need you (We need you, of the Lord)\n",
      "We need you (Comes)\n",
      "Oh, we need you (Down)\n",
      "\n",
      "\n",
      "[Verse]\n",
      "Sing 'til the power of the Lord comes down\n",
      "Sing 'til the power of the Lord comes down\n",
      "Sing 'til the power of the Lord comes down (Let everything that have breath praise God)\n",
      "Sing 'til the power of the Lord comes down ('Cause when we sing the glory of the Lord comes down, down)\n",
      "Sing 'til the power of the Lord comes down (Praising the Lord, praise God in the sanctuary)\n",
      "Sing 'til the power of the Lord comes down (For His mighty works and excellent grace and His mighty power, yeah)\n",
      "Sing 'til the power of the Lord comes down (Sing 'til the power of the Lord falls down)\n",
      "Sing 'til the power of the Lord comes down (We are to sing 'til the power of the Lord comes down)\n",
      "Sing 'til the power of\n"
     ]
    }
   ],
   "source": [
    "print('First 1000 characters:\\n ', lyrics[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 vocabulary size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " !\"#$&'()*+,-./0123456789:;?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]abcdefghijklmnopqrstuvwxyzÁáéñóöúāŐ–—‘’“”…⁠﻿\n",
      "Number of unique characters:  101\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(lyrics)))\n",
    "vocab_size = len(chars)\n",
    "print(''.join(c for c in chars))\n",
    "print('Number of unique characters: ', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: encoding and decoding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 encode and decode functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[64, 65, 65, 1, 76, 64, 61, 74, 61]\n",
      "hii there\n"
     ]
    }
   ],
   "source": [
    "stoi = { ch:i for i,ch in enumerate(chars) }\n",
    "itos = { i:ch for i,ch in enumerate(chars) }\n",
    "encode = lambda s : [stoi[c] for c in s]\n",
    "decode = lambda l : ''.join([itos[c] for c in l])\n",
    "print(encode('hii there'))\n",
    "print(decode(encode('hii there')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[83, 70, 60, 57, 68, 61, 12, 1, 84, 70, 60, 57, 68, 61, 1, 33, 14, 37, 12, 1, 33, 14, 37, 12, 1, 77, 64, 13, 71, 64]\n",
      "Ándale, ándale E.I, E.I, uh-oh\n"
     ]
    }
   ],
   "source": [
    "print(encode(\"Ándale, ándale E.I, E.I, uh-oh\"))\n",
    "print(decode(encode(\"Ándale, ándale E.I, E.I, uh-oh\")))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 encode the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([353441]) torch.int64\n",
      "tensor([100,  55,  31,  64,  71,  74,  77,  75,  56,   0,  47,  65,  70,  63,\n",
      "          1,  61,  78,  61,  74,  81,   1,  64,  71,  77,  74,   1,   8,  33,\n",
      "         78,  61,  74,  81,   1,  64,  71,  77,  74,  12,   1,   7,  76,  65,\n",
      "         68,   1,  76,  64,  61,   1,  72,  71,  79,  61,  74,   9,   0,  33,\n",
      "         78,  61,  74,  81,   1,  69,  65,  70,  77,  76,  61,   1,   8,  33,\n",
      "         78,  61,  74,  81,   1,  69,  65,  70,  77,  76,  61,  12,   1,  71,\n",
      "         62,   1,  76,  64,  61,   1,  40,  71,  74,  60,   9,   0,  33,  78,\n",
      "         61,  74,  81,   1,  75,  61,  59,  71,  70,  60,   1,   8,  33,  78,\n",
      "         61,  74,  81,   1,  75,  61,  59,  71,  70,  60,  12,   1,  59,  71,\n",
      "         69,  61,  75,   9,   0,  47,  65,  70,  63,   1,  61,  57,  59,  64,\n",
      "          1,  57,  70,  60,   1,  61,  78,  61,  74,  81,   1,  69,  65,  68,\n",
      "         68,  65,  75,  61,  59,  71,  70,  60,   1,   8,  32,  71,  79,  70,\n",
      "          9,   0,  51,  61,   1,  70,  61,  61,  60,   1,  81,  71,  77,   1,\n",
      "          8,  51,  61,   1,  70,  61,  61,  60,   1,  81,  71,  77,  12,   1,\n",
      "         75,  65,  70,  63,   1,   7,  76,  65,  68,   1,  76,  64,  61,   1,\n",
      "         72,  71,  79,  61,  74,   9,   0,  51,  61,   1,  70,  61,  61,  60,\n",
      "          1,  81,  71,  77,   1,   8,  51,  61,   1,  70,  61,  61,  60,   1,\n",
      "         81,  71,  77,  12,   1,  71,  62,   1,  76,  64,  61,   1,  40,  71,\n",
      "         74,  60,   9,   0,  51,  61,   1,  70,  61,  61,  60,   1,  81,  71,\n",
      "         77,   1,   8,  31,  71,  69,  61,  75,   9,   0,  43,  64,  12,   1,\n",
      "         79,  61,   1,  70,  61,  61,  60,   1,  81,  71,  77,   1,   8,  32,\n",
      "         71,  79,  70,   9,   0,   0,   0,  55,  50,  61,  74,  75,  61,  56,\n",
      "          0,  47,  65,  70,  63,   1,   7,  76,  65,  68,   1,  76,  64,  61,\n",
      "          1,  72,  71,  79,  61,  74,   1,  71,  62,   1,  76,  64,  61,   1,\n",
      "         40,  71,  74,  60,   1,  59,  71,  69,  61,  75,   1,  60,  71,  79,\n",
      "         70,   0,  47,  65,  70,  63,   1,   7,  76,  65,  68,   1,  76,  64,\n",
      "         61,   1,  72,  71,  79,  61,  74,   1,  71,  62,   1,  76,  64,  61,\n",
      "          1,  40,  71,  74,  60,   1,  59,  71,  69,  61,  75,   1,  60,  71,\n",
      "         79,  70,   0,  47,  65,  70,  63,   1,   7,  76,  65,  68,   1,  76,\n",
      "         64,  61,   1,  72,  71,  79,  61,  74,   1,  71,  62,   1,  76,  64,\n",
      "         61,   1,  40,  71,  74,  60,   1,  59,  71,  69,  61,  75,   1,  60,\n",
      "         71,  79,  70,   1,   8,  40,  61,  76,   1,  61,  78,  61,  74,  81,\n",
      "         76,  64,  65,  70,  63,   1,  76,  64,  57,  76,   1,  64,  57,  78,\n",
      "         61,   1,  58,  74,  61,  57,  76,  64,   1,  72,  74,  57,  65,  75,\n",
      "         61,   1,  35,  71,  60,   9,   0,  47,  65,  70,  63,   1,   7,  76,\n",
      "         65,  68,   1,  76,  64,  61,   1,  72,  71,  79,  61,  74,   1,  71,\n",
      "         62,   1,  76,  64,  61,   1,  40,  71,  74,  60,   1,  59,  71,  69,\n",
      "         61,  75,   1,  60,  71,  79,  70,   1,   8,   7,  31,  57,  77,  75,\n",
      "         61,   1,  79,  64,  61,  70,   1,  79,  61,   1,  75,  65,  70,  63,\n",
      "          1,  76,  64,  61,   1,  63,  68,  71,  74,  81,   1,  71,  62,   1,\n",
      "         76,  64,  61,   1,  40,  71,  74,  60,   1,  59,  71,  69,  61,  75,\n",
      "          1,  60,  71,  79,  70,  12,   1,  60,  71,  79,  70,   9,   0,  47,\n",
      "         65,  70,  63,   1,   7,  76,  65,  68,   1,  76,  64,  61,   1,  72,\n",
      "         71,  79,  61,  74,   1,  71,  62,   1,  76,  64,  61,   1,  40,  71,\n",
      "         74,  60,   1,  59,  71,  69,  61,  75,   1,  60,  71,  79,  70,   1,\n",
      "          8,  44,  74,  57,  65,  75,  65,  70,  63,   1,  76,  64,  61,   1,\n",
      "         40,  71,  74,  60,  12,   1,  72,  74,  57,  65,  75,  61,   1,  35,\n",
      "         71,  60,   1,  65,  70,   1,  76,  64,  61,   1,  75,  57,  70,  59,\n",
      "         76,  77,  57,  74,  81,   9,   0,  47,  65,  70,  63,   1,   7,  76,\n",
      "         65,  68,   1,  76,  64,  61,   1,  72,  71,  79,  61,  74,   1,  71,\n",
      "         62,   1,  76,  64,  61,   1,  40,  71,  74,  60,   1,  59,  71,  69,\n",
      "         61,  75,   1,  60,  71,  79,  70,   1,   8,  34,  71,  74,   1,  36,\n",
      "         65,  75,   1,  69,  65,  63,  64,  76,  81,   1,  79,  71,  74,  67,\n",
      "         75,   1,  57,  70,  60,   1,  61,  80,  59,  61,  68,  68,  61,  70,\n",
      "         76,   1,  63,  74,  57,  59,  61,   1,  57,  70,  60,   1,  36,  65,\n",
      "         75,   1,  69,  65,  63,  64,  76,  81,   1,  72,  71,  79,  61,  74,\n",
      "         12,   1,  81,  61,  57,  64,   9,   0,  47,  65,  70,  63,   1,   7,\n",
      "         76,  65,  68,   1,  76,  64,  61,   1,  72,  71,  79,  61,  74,   1,\n",
      "         71,  62,   1,  76,  64,  61,   1,  40,  71,  74,  60,   1,  59,  71,\n",
      "         69,  61,  75,   1,  60,  71,  79,  70,   1,   8,  47,  65,  70,  63,\n",
      "          1,   7,  76,  65,  68,   1,  76,  64,  61,   1,  72,  71,  79,  61,\n",
      "         74,   1,  71,  62,   1,  76,  64,  61,   1,  40,  71,  74,  60,   1,\n",
      "         62,  57,  68,  68,  75,   1,  60,  71,  79,  70,   9,   0,  47,  65,\n",
      "         70,  63,   1,   7,  76,  65,  68,   1,  76,  64,  61,   1,  72,  71,\n",
      "         79,  61,  74,   1,  71,  62,   1,  76,  64,  61,   1,  40,  71,  74,\n",
      "         60,   1,  59,  71,  69,  61,  75,   1,  60,  71,  79,  70,   1,   8,\n",
      "         51,  61,   1,  57,  74,  61,   1,  76,  71,   1,  75,  65,  70,  63,\n",
      "          1,   7,  76,  65,  68,   1,  76,  64,  61,   1,  72,  71,  79,  61,\n",
      "         74,   1,  71,  62,   1,  76,  64,  61,   1,  40,  71,  74,  60,   1,\n",
      "         59,  71,  69,  61,  75,   1,  60,  71,  79,  70,   9,   0,  47,  65,\n",
      "         70,  63,   1,   7,  76,  65,  68,   1,  76,  64,  61,   1,  72,  71,\n",
      "         79,  61,  74,   1,  71,  62])\n"
     ]
    }
   ],
   "source": [
    "data = torch.tensor(encode(lyrics), dtype=torch.long)\n",
    "print(data.shape, data.dtype)\n",
    "print(data[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3: data split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = 0.9\n",
    "n = int(train_split * len(data))\n",
    "train_data = data[:n]\n",
    "val_data = data[n:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 note on training\n",
    "\n",
    "When we train the model, we will not process the entire dataset at once, nor will we train on single character pairs. Instead, we will decide on a size of a block of text to look at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([100,  55,  31,  64,  71,  74,  77,  75,  56])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# start with block_size = 8\n",
    "block_size = 8\n",
    "train_data[:block_size+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When input is tensor([100]) the target is 55\n",
      "When input is tensor([100,  55]) the target is 31\n",
      "When input is tensor([100,  55,  31]) the target is 64\n",
      "When input is tensor([100,  55,  31,  64]) the target is 71\n",
      "When input is tensor([100,  55,  31,  64,  71]) the target is 74\n",
      "When input is tensor([100,  55,  31,  64,  71,  74]) the target is 77\n",
      "When input is tensor([100,  55,  31,  64,  71,  74,  77]) the target is 75\n",
      "When input is tensor([100,  55,  31,  64,  71,  74,  77,  75]) the target is 56\n",
      "When input is ﻿ the target is [\n",
      "When input is ﻿[ the target is C\n",
      "When input is ﻿[C the target is h\n",
      "When input is ﻿[Ch the target is o\n",
      "When input is ﻿[Cho the target is r\n",
      "When input is ﻿[Chor the target is u\n",
      "When input is ﻿[Choru the target is s\n",
      "When input is ﻿[Chorus the target is ]\n"
     ]
    }
   ],
   "source": [
    "x = train_data[:block_size]\n",
    "y = train_data[1:block_size+1]\n",
    "for t in range(block_size):\n",
    "    context = x[:t+1]\n",
    "    target = y[t]\n",
    "    print(f\"When input is {context} the target is {target}\")\n",
    "for t in range(block_size):\n",
    "    context = decode(x[:t+1].tolist())\n",
    "    target = decode([y[t].item()])\n",
    "    print(f\"When input is {context} the target is {target}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "torch.Size([4, 8])\n",
      "tensor([[61,  0, 47, 64, 61,  1, 79, 57],\n",
      "        [ 1, 60, 71, 70,  7, 76,  1, 79],\n",
      "        [71, 70,  1, 69, 81,  1, 79, 57],\n",
      "        [76, 81,  0, 51, 61,  1, 61, 74]])\n",
      "targets:\n",
      "torch.Size([4, 8])\n",
      "tensor([[ 0, 47, 64, 61,  1, 79, 57, 70],\n",
      "        [60, 71, 70,  7, 76,  1, 79, 71],\n",
      "        [70,  1, 69, 81,  1, 79, 57, 65],\n",
      "        [81,  0, 51, 61,  1, 61, 74, 57]])\n",
      "----\n",
      "When input is [61] the target is 0\n",
      "When input is [61, 0] the target is 47\n",
      "When input is [61, 0, 47] the target is 64\n",
      "When input is [61, 0, 47, 64] the target is 61\n",
      "When input is [61, 0, 47, 64, 61] the target is 1\n",
      "When input is [61, 0, 47, 64, 61, 1] the target is 79\n",
      "When input is [61, 0, 47, 64, 61, 1, 79] the target is 57\n",
      "When input is [61, 0, 47, 64, 61, 1, 79, 57] the target is 70\n",
      "When input is [1] the target is 60\n",
      "When input is [1, 60] the target is 71\n",
      "When input is [1, 60, 71] the target is 70\n",
      "When input is [1, 60, 71, 70] the target is 7\n",
      "When input is [1, 60, 71, 70, 7] the target is 76\n",
      "When input is [1, 60, 71, 70, 7, 76] the target is 1\n",
      "When input is [1, 60, 71, 70, 7, 76, 1] the target is 79\n",
      "When input is [1, 60, 71, 70, 7, 76, 1, 79] the target is 71\n",
      "When input is [71] the target is 70\n",
      "When input is [71, 70] the target is 1\n",
      "When input is [71, 70, 1] the target is 69\n",
      "When input is [71, 70, 1, 69] the target is 81\n",
      "When input is [71, 70, 1, 69, 81] the target is 1\n",
      "When input is [71, 70, 1, 69, 81, 1] the target is 79\n",
      "When input is [71, 70, 1, 69, 81, 1, 79] the target is 57\n",
      "When input is [71, 70, 1, 69, 81, 1, 79, 57] the target is 65\n",
      "When input is [76] the target is 81\n",
      "When input is [76, 81] the target is 0\n",
      "When input is [76, 81, 0] the target is 51\n",
      "When input is [76, 81, 0, 51] the target is 61\n",
      "When input is [76, 81, 0, 51, 61] the target is 1\n",
      "When input is [76, 81, 0, 51, 61, 1] the target is 61\n",
      "When input is [76, 81, 0, 51, 61, 1, 61] the target is 74\n",
      "When input is [76, 81, 0, 51, 61, 1, 61, 74] the target is 57\n"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(1337)\n",
    "batch_size = 4\n",
    "block_size = 8\n",
    "\n",
    "def get_batch(split):\n",
    "    # generate  a small batch of data of inputs x and target y\n",
    "    data = train_data if split=='train' else val_data\n",
    "    ix = torch.randint(len(data)-block_size, size=(batch_size,))\n",
    "    x = torch.stack([data[i:i+block_size] for i in ix])\n",
    "    y = torch.stack([data[i+1:i+block_size+1] for i in ix])\n",
    "    return x, y\n",
    "\n",
    "xb, yb = get_batch('train')\n",
    "print('inputs:')\n",
    "print(xb.shape)\n",
    "print(xb)\n",
    "print('targets:')\n",
    "print(yb.shape)\n",
    "print(yb)\n",
    "\n",
    "print('----')\n",
    "\n",
    "for b in range(batch_size):\n",
    "    for t in range(block_size):\n",
    "        context = xb[b, :t+1]\n",
    "        target = yb[b, t]\n",
    "        print(f\"When input is {context.tolist()} the target is {target}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3: Implementing networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 the bigram language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 8, 101])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.nn import functional as F\n",
    "torch.manual_seed(1337)\n",
    "\n",
    "class BigramLangaugeModel(nn.Module):\n",
    "\n",
    "    def __init__(self, vocab_size):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.token_embedding_table = nn.Embedding(vocab_size, vocab_size)\n",
    "\n",
    "    def forward(self, idx, targets):\n",
    "\n",
    "        # idx and targets are both (B,T) tensors of integers\n",
    "        logits = self.token_embedding_table(idx) # (B,T,C)\n",
    "\n",
    "        return logits\n",
    "\n",
    "m = BigramLangaugeModel(vocab_size)\n",
    "out = m(xb, yb)\n",
    "print(out.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c17ef166827587e58f5e1d9fc37d7d71128d9ee001cf728f6b987f1c2dd16782"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
